{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF OCR Text Conversion Pipeline\n",
    "\n",
    "**Purpose:**  \n",
    "Automate OCR‐based text extraction from PDF certificates, classify pages/documents by readability, and export both the text and a summary of key metrics.\n",
    "\n",
    "**Inputs:**  \n",
    "- A folder of `.pdf` documents (e.g. Certificates of Incorporation).\n",
    "\n",
    "**Outputs:**  \n",
    "1. A `pandas.DataFrame` summarizing, for each PDF:  \n",
    "   - File name  \n",
    "   - Number of characters & words extracted  \n",
    "   - OCR confidence level  \n",
    "   - Composite readability score  \n",
    "   - Quality label (`readable`/`unreadable`)  \n",
    "2. Text files saved to **readable** and **unreadable** subfolders.  \n",
    "3. Console/log output of summary metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Environment Setup](#setup)  \n",
    "2. [Configuration](#config)  \n",
    "3. [Preprocessing Functions](#preproc)  \n",
    "4. [OCR Extraction Functions](#ocr)  \n",
    "5. [Readability Classification](#readability)  \n",
    "6. [Processing Pipeline](#pipeline)  \n",
    "7. [Run Pipeline](#run)  \n",
    "8. [Results Analysis](#analysis)  \n",
    "9. [Summary Metrics](#metrics)  \n",
    "10. [Next Steps & Extensions](#next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environment Setup\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s — %(levelname)s — %(message)s\")\n",
    "\n",
    "# Point pytesseract at your Tesseract installation (adjust path as needed)\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\Owner\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Load English vocabulary for word‐list checks\n",
    "english_vocab = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configuration\n",
    "\n",
    "# Base directory containing your PDF batches\n",
    "BASE_DIR = Path(\"D:/vc-research/vc-research\")\n",
    "\n",
    "# Define batch folders and output folders\n",
    "BATCHES = {\n",
    "    \"Batch1\": {\n",
    "        \"input\": BASE_DIR / \"Batch1\",\n",
    "        \"readable\": BASE_DIR / \"Batch1_text_readable\",\n",
    "        \"unreadable\": BASE_DIR / \"Batch1_text_unreadable\"\n",
    "    },\n",
    "    \"Batch2\": {\n",
    "        \"input\": BASE_DIR / \"Batch2\",\n",
    "        \"readable\": BASE_DIR / \"Batch2_text_readable\",\n",
    "        \"unreadable\": BASE_DIR / \"Batch2_text_unreadable\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "for cfg in BATCHES.values():\n",
    "    cfg[\"readable\"].mkdir(parents=True, exist_ok=True)\n",
    "    cfg[\"unreadable\"].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# OCR & classification parameters\n",
    "OCR_DPI = 300                  # DPI for pdf2image conversion\n",
    "READABILITY_THRESHOLD = 0.6    # Composite score threshold\n",
    "MAX_WORKERS = os.cpu_count()   # Parallel threads\n",
    "EXPORT_TEXT = True             # Whether to save extracted text to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions\n",
    "Simplify images for better OCR accuracy (e.g., grayscale conversion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess pdfs for better OCR results\n",
    "def preprocess_image(img: Image.Image) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Convert the input image to grayscale to improve OCR accuracy.\n",
    "    \"\"\"\n",
    "    return img.convert(\"L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tesseract_confidence(img: Image.Image) -> float:\n",
    "    \"\"\"\n",
    "    Run Tesseract word‐level OCR on the image and return the average confidence.\n",
    "    \"\"\"\n",
    "    data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "    # Filter out missing confidences marked as '-1'\n",
    "    confs = [int(c) for c in data[\"conf\"] if c != \"-1\"]\n",
    "    return float(np.mean(confs)) if confs else 0.0\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Convert each page of the PDF to an image, preprocess it, and OCR the text.\n",
    "    Returns the concatenated text for the entire document.\n",
    "    \"\"\"\n",
    "    text_parts = []\n",
    "    try:\n",
    "        pages = convert_from_path(str(pdf_path), dpi=OCR_DPI)\n",
    "        for page in pages:\n",
    "            img = preprocess_image(page)\n",
    "            text_parts.append(pytesseract.image_to_string(img, lang=\"eng\"))\n",
    "        return \"\\n\".join(text_parts)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to OCR {pdf_path.name}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability Classification\n",
    "Combine OCR confidence with English‐word coverage to decide readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_readable_text(img: Image.Image, text: str, threshold: float = READABILITY_THRESHOLD) -> bool:\n",
    "    \"\"\"\n",
    "    Compute a composite score:\n",
    "      70% weight → normalized Tesseract confidence (0–1)\n",
    "      30% weight → fraction of words in English vocab\n",
    "    Returns True if composite score ≥ threshold.\n",
    "    \"\"\"\n",
    "    # 1) OCR confidence component\n",
    "    conf_score = get_tesseract_confidence(img) / 100.0\n",
    "\n",
    "    # 2) English‐word coverage\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "    if not tokens:\n",
    "        return False\n",
    "    valid = sum(1 for w in tokens if w in english_vocab) / len(tokens)\n",
    "\n",
    "    composite = 0.7 * conf_score + 0.3 * valid\n",
    "    return composite >= threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Pipeline\n",
    "Process each PDF: OCR → metrics → classification → optional text export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(\n",
    "    pdf_path: Path,\n",
    "    readable_dir: Path,\n",
    "    unreadable_dir: Path,\n",
    "    threshold: float = READABILITY_THRESHOLD,\n",
    "    export_text: bool = EXPORT_TEXT\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    For a single PDF:\n",
    "      • OCR each page\n",
    "      • Compute metrics: #chars, #words, avg. confidence, composite score\n",
    "      • Label as 'readable' or 'unreadable'\n",
    "      • Optionally save text to the corresponding folder\n",
    "      • Return a dict of metrics\n",
    "    \"\"\"\n",
    "    logging.info(f\"Processing {pdf_path.name}\")\n",
    "    metrics = {\"file_name\": pdf_path.name}\n",
    "\n",
    "    try:\n",
    "        pages = convert_from_path(str(pdf_path), dpi=OCR_DPI, poppler_path=r\"C:\\poppler-24.08.0\\Library\\bin\")\n",
    "        all_text = []\n",
    "        confidences = []\n",
    "\n",
    "        for page in pages:\n",
    "            img = preprocess_image(page)\n",
    "            txt = pytesseract.image_to_string(img, lang=\"eng\")\n",
    "            all_text.append(txt)\n",
    "            confidences.append(get_tesseract_confidence(img))\n",
    "\n",
    "        full_text = \"\\n\".join(all_text)\n",
    "        char_count = len(full_text)\n",
    "        word_count = len(re.findall(r\"\\b\\w+\\b\", full_text))\n",
    "        avg_conf = float(np.mean(confidences)) if confidences else 0.0\n",
    "\n",
    "        # Re‐apply readability logic on full document\n",
    "        tokens = re.findall(r\"\\b\\w+\\b\", full_text.lower())\n",
    "        valid_pct = (sum(1 for w in tokens if w in english_vocab) / len(tokens)) if tokens else 0.0\n",
    "        composite = 0.7 * (avg_conf / 100.0) + 0.3 * valid_pct\n",
    "        label = \"readable\" if composite >= threshold else \"unreadable\"\n",
    "\n",
    "        # Save text file, if desired\n",
    "        if export_text:\n",
    "            out_dir = readable_dir if label == \"readable\" else unreadable_dir\n",
    "            txt_path = out_dir / f\"{pdf_path.stem}.txt\"\n",
    "            txt_path.write_text(full_text, encoding=\"utf-8\")\n",
    "\n",
    "        # Populate metrics dict\n",
    "        metrics.update({\n",
    "            \"number_of_characters\": char_count,\n",
    "            \"number_of_words\": word_count,\n",
    "            \"confidence_level\": avg_conf,\n",
    "            \"composite_score\": composite,\n",
    "            \"quality\": label\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in {pdf_path.name}: {e}\")\n",
    "        # On failure, mark as unreadable with zero metrics\n",
    "        metrics.update({\n",
    "            \"number_of_characters\": 0,\n",
    "            \"number_of_words\": 0,\n",
    "            \"confidence_level\": 0.0,\n",
    "            \"composite_score\": 0.0,\n",
    "            \"quality\": \"unreadable\"\n",
    "        })\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs(\n",
    "    folder: Path,\n",
    "    readable_dir: Path,\n",
    "    unreadable_dir: Path,\n",
    "    threshold: float = READABILITY_THRESHOLD,\n",
    "    limit: int = None,\n",
    "    export_text: bool = EXPORT_TEXT\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process every PDF in `folder` in parallel, returning a DataFrame of results.\n",
    "    \"\"\"\n",
    "    pdfs = list(folder.glob(\"*.pdf\"))\n",
    "    if limit:\n",
    "        pdfs = pdfs[:limit]\n",
    "\n",
    "    # Map PDFs → metrics dicts\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as exec:\n",
    "        results = list(exec.map(\n",
    "            lambda p: process_pdf(p, readable_dir, unreadable_dir, threshold, export_text),\n",
    "            pdfs\n",
    "        ))\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Pipeline\n",
    "Kick off processing for one batch (adjust name to switch batches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 19:42:25,168 — INFO — Processing 100_2007-02-22_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,171 — INFO — Processing 100_2008-12-03_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,173 — INFO — Processing 10_2006-09-13_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,174 — INFO — Processing 16_2003-07-03_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,178 — INFO — Processing 16_2004-01-22_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,180 — INFO — Processing 16_2004-07-14_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,195 — INFO — Processing 16_2005-05-18_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,195 — INFO — Processing 16_2006-03-09_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,196 — INFO — Processing 16_2007-05-16_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,197 — INFO — Processing 16_2008-03-03_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,206 — INFO — Processing 16_2009-01-20_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,207 — INFO — Processing 16_2011-03-10_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,213 — INFO — Processing 16_2011-03-11_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,217 — INFO — Processing 16_2012-12-17_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,218 — INFO — Processing 16_2015-04-22_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:25,222 — INFO — Processing 21_2006-04-21_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:29,150 — INFO — Processing 24_2004-12-01_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:30,613 — INFO — Processing 24_2005-10-20_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:32,449 — INFO — Processing 24_2006-09-14_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:34,264 — INFO — Processing 24_2007-06-28_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:40,295 — INFO — Processing 24_2008-08-21_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:40,430 — INFO — Processing 24_2009-06-12_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:45,118 — INFO — Processing 24_2009-07-20_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:48,292 — INFO — Processing 24_2011-05-05_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:57,680 — INFO — Processing 24_2012-01-10_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:42:58,563 — INFO — Processing 24_2014-08-27_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:00,236 — INFO — Processing 24_2016-04-04_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:02,054 — INFO — Processing 24_2018-03-02_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:08,473 — INFO — Processing 24_2018-04-03_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:10,783 — INFO — Processing 27_2002-09-23_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:13,280 — INFO — Processing 27_2004-06-16_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:22,691 — INFO — Processing 27_2004-08-17_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:22,962 — INFO — Processing 27_2005-12-22_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:32,113 — INFO — Processing 27_2006-08-23_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:43:45,103 — INFO — Processing 27_2006-08-30_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:44:50,474 — INFO — Processing 27_2008-07-31_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:44:59,036 — INFO — Processing 27_2008-11-13_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:00,139 — INFO — Processing 27_2009-05-15_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:01,196 — INFO — Processing 27_2009-08-04_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:04,839 — INFO — Processing 27_2010-09-16_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:08,600 — INFO — Processing 27_2010-10-10_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:10,268 — INFO — Processing 27_2013-09-26_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:10,673 — INFO — Processing 28_2007-06-15_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:14,393 — INFO — Processing 28_2009-12-07_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:14,403 — INFO — Processing 28_2009-12-17_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:14,534 — INFO — Processing 28_2012-03-16_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:16,995 — INFO — Processing 28_2012-05-09_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:17,521 — INFO — Processing 34_2008-09-29_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:23,202 — INFO — Processing 34_2010-01-28_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:27,252 — INFO — Processing 35_2007-06-20_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:28,676 — INFO — Processing 35_2007-10-29_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:30,718 — INFO — Processing 35_2013-03-04_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:45:31,037 — INFO — Processing 35_2017-09-29_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:46:12,357 — INFO — Processing 35_2018-02-23_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:02,540 — INFO — Processing 43_2005-10-31_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:10,641 — INFO — Processing 43_2007-01-26_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:13,340 — INFO — Processing 45_2008-01-17_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:21,339 — INFO — Processing 48_2004-07-29_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:27,055 — INFO — Processing 48_2004-10-08_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:29,039 — INFO — Processing 48_2004-10-19_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:31,955 — INFO — Processing 48_2005-04-11_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:37,180 — INFO — Processing 48_2005-06-30_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:39,923 — INFO — Processing 48_2006-07-25_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:44,708 — INFO — Processing 48_2006-09-14_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:50,657 — INFO — Processing 48_2008-02-25_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:53,324 — INFO — Processing 48_2009-03-30_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:54,719 — INFO — Processing 48_2011-03-30_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:47:56,930 — INFO — Processing 48_2013-06-27_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:03,597 — INFO — Processing 48_2013-12-06_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:13,502 — INFO — Processing 48_2014-03-06_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:15,895 — INFO — Processing 49_2006-01-30_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:24,673 — INFO — Processing 49_2007-01-23_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:25,345 — INFO — Processing 49_2007-08-03_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:39,565 — INFO — Processing 49_2008-05-06_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:41,026 — INFO — Processing 49_2008-06-12_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:41,268 — INFO — Processing 59_2006-05-01_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:48:56,951 — INFO — Processing 59_2007-08-15_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:49:03,402 — INFO — Processing 63_2007-05-24_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:49:27,641 — INFO — Processing 65_2010-04-05_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:49:27,767 — INFO — Processing 66_2004-02-11_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:49:30,076 — INFO — Processing 77_2004-10-25_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:49:36,815 — INFO — Processing 81_2006-07-28_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:49:44,325 — INFO — Processing 81_2007-10-23_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:49:46,730 — INFO — Processing 81_2009-11-06_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:49:54,325 — INFO — Processing 81_2009-12-03_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:50:04,237 — INFO — Processing 81_2010-03-17_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:50:16,577 — INFO — Processing 81_2010-06-10_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:50:47,384 — INFO — Processing 81_2011-12-22_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:51:05,007 — INFO — Processing 89_2010-12-07_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:51:15,879 — INFO — Processing 92_2004-11-23_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:51:17,266 — INFO — Processing 92_2007-12-20_Certificates of Incorporation.pdf\n",
      "2025-07-14 19:51:18,020 — INFO — Processing 92_2010-02-23_Certificates of Incorporation.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>number_of_characters</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>confidence_level</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_2007-02-22_Certificates of Incorporation.pdf</td>\n",
       "      <td>48801</td>\n",
       "      <td>7983</td>\n",
       "      <td>83.845956</td>\n",
       "      <td>0.841901</td>\n",
       "      <td>readable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100_2008-12-03_Certificates of Incorporation.pdf</td>\n",
       "      <td>58477</td>\n",
       "      <td>9529</td>\n",
       "      <td>83.415060</td>\n",
       "      <td>0.834131</td>\n",
       "      <td>readable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_2006-09-13_Certificates of Incorporation.pdf</td>\n",
       "      <td>86</td>\n",
       "      <td>13</td>\n",
       "      <td>43.291667</td>\n",
       "      <td>0.441503</td>\n",
       "      <td>unreadable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16_2003-07-03_Certificates of Incorporation.pdf</td>\n",
       "      <td>2283</td>\n",
       "      <td>372</td>\n",
       "      <td>79.729604</td>\n",
       "      <td>0.796817</td>\n",
       "      <td>readable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16_2004-01-22_Certificates of Incorporation.pdf</td>\n",
       "      <td>6134</td>\n",
       "      <td>980</td>\n",
       "      <td>77.905922</td>\n",
       "      <td>0.792382</td>\n",
       "      <td>readable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_name  number_of_characters  \\\n",
       "0  100_2007-02-22_Certificates of Incorporation.pdf                 48801   \n",
       "1  100_2008-12-03_Certificates of Incorporation.pdf                 58477   \n",
       "2   10_2006-09-13_Certificates of Incorporation.pdf                    86   \n",
       "3   16_2003-07-03_Certificates of Incorporation.pdf                  2283   \n",
       "4   16_2004-01-22_Certificates of Incorporation.pdf                  6134   \n",
       "\n",
       "   number_of_words  confidence_level  composite_score     quality  \n",
       "0             7983         83.845956         0.841901    readable  \n",
       "1             9529         83.415060         0.834131    readable  \n",
       "2               13         43.291667         0.441503  unreadable  \n",
       "3              372         79.729604         0.796817    readable  \n",
       "4              980         77.905922         0.792382    readable  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: run on Batch1\n",
    "batch_cfg = BATCHES[\"Batch1\"]\n",
    "results_df = process_all_pdfs(\n",
    "    folder=batch_cfg[\"input\"],\n",
    "    readable_dir=batch_cfg[\"readable\"],\n",
    "    unreadable_dir=batch_cfg[\"unreadable\"]\n",
    ")\n",
    "\n",
    "# Display the first few results\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "Quick look at overall distribution of quality labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.28188975688529"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['confidence_level'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "readable      89\n",
       "unreadable     3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of readable vs. unreadable\n",
    "results_df[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>number_of_characters</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>confidence_level</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_2006-09-13_Certificates of Incorporation.pdf</td>\n",
       "      <td>86</td>\n",
       "      <td>13</td>\n",
       "      <td>43.291667</td>\n",
       "      <td>0.441503</td>\n",
       "      <td>unreadable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16_2015-04-22_Certificates of Incorporation.pdf</td>\n",
       "      <td>591</td>\n",
       "      <td>100</td>\n",
       "      <td>60.858209</td>\n",
       "      <td>0.597007</td>\n",
       "      <td>unreadable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>27_2008-11-13_Certificates of Incorporation.pdf</td>\n",
       "      <td>554</td>\n",
       "      <td>113</td>\n",
       "      <td>28.209933</td>\n",
       "      <td>0.340832</td>\n",
       "      <td>unreadable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_name  number_of_characters  \\\n",
       "2   10_2006-09-13_Certificates of Incorporation.pdf                    86   \n",
       "14  16_2015-04-22_Certificates of Incorporation.pdf                   591   \n",
       "36  27_2008-11-13_Certificates of Incorporation.pdf                   554   \n",
       "\n",
       "    number_of_words  confidence_level  composite_score     quality  \n",
       "2                13         43.291667         0.441503  unreadable  \n",
       "14              100         60.858209         0.597007  unreadable  \n",
       "36              113         28.209933         0.340832  unreadable  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample unreadable documents for manual review\n",
    "results_df[results_df[\"quality\"] == \"unreadable\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>number_of_characters</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>confidence_level</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_2006-09-13_Certificates of Incorporation.pdf</td>\n",
       "      <td>86</td>\n",
       "      <td>13</td>\n",
       "      <td>43.291667</td>\n",
       "      <td>0.441503</td>\n",
       "      <td>unreadable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16_2015-04-22_Certificates of Incorporation.pdf</td>\n",
       "      <td>591</td>\n",
       "      <td>100</td>\n",
       "      <td>60.858209</td>\n",
       "      <td>0.597007</td>\n",
       "      <td>unreadable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>27_2008-11-13_Certificates of Incorporation.pdf</td>\n",
       "      <td>554</td>\n",
       "      <td>113</td>\n",
       "      <td>28.209933</td>\n",
       "      <td>0.340832</td>\n",
       "      <td>unreadable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_name  number_of_characters  \\\n",
       "2   10_2006-09-13_Certificates of Incorporation.pdf                    86   \n",
       "14  16_2015-04-22_Certificates of Incorporation.pdf                   591   \n",
       "36  27_2008-11-13_Certificates of Incorporation.pdf                   554   \n",
       "\n",
       "    number_of_words  confidence_level  composite_score     quality  \n",
       "2                13         43.291667         0.441503  unreadable  \n",
       "14              100         60.858209         0.597007  unreadable  \n",
       "36              113         28.209933         0.340832  unreadable  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample unreadable documents for manual review\n",
    "results_df[results_df[\"quality\"] == \"unreadable\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Metrics\n",
    "Compute overall readability rates for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch1: 90/92 readable (97.8%), 3.3% unreadable\n",
      "Batch2: 948/950 readable (99.8%), 0.2% unreadable\n"
     ]
    }
   ],
   "source": [
    "for name, cfg in BATCHES.items():\n",
    "    total_pdfs = len(list(cfg[\"input\"].glob(\"*.pdf\")))\n",
    "    readable_txt = len(list(cfg[\"readable\"].glob(\"*.txt\")))\n",
    "    unreadable_txt = len(list(cfg[\"unreadable\"].glob(\"*.txt\")))\n",
    "\n",
    "    print(\n",
    "        f\"{name}: {readable_txt}/{total_pdfs} readable \"\n",
    "        f\"({readable_txt/total_pdfs:.1%}), \"\n",
    "        f\"{unreadable_txt/total_pdfs:.1%} unreadable\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps & Extensions\n",
    "\n",
    "- **Logging to File:** route `INFO`/`ERROR` logs to a timestamped logfile.  \n",
    "- **Unit Tests:** build `pytest` tests for each function (`preprocess_image`, `get_tesseract_confidence`, etc.).  \n",
    "- **Error Tracking:** record failed PDFs into a CSV for manual triage.  \n",
    "- **Advanced Models:** integrate an LLM or fine‐tuned Vision+OCR model for edge‐case pages.  \n",
    "- **Parallel Tuning:** experiment with chunk sizes or GPU‐accelerated OCR for speed.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
