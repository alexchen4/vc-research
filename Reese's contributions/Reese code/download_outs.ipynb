{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26841b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_79_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_78_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_77_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_76_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_75_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_74_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_73_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_72_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_71_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_70_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_69_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_68_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_67_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_66_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_65_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_64_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_63_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_62_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_61_G2_out.jsonl\n",
      "✅  Saved: D:\\vc-research\\reese data\\downloaded_batches\\batch_60_G2_out.jsonl\n",
      "↷ Batch batch_689e80d186a08190a1ff335bbaa63b77: status=failed (not downloaded)\n",
      "⏭️  batch_60_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_59_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_58_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_57_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_56_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_55_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_54_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_53_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_52_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_51_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_50_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_49_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_48_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_47_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_46_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_45_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_44_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_43_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_42_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_41_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_40_G2_out.jsonl already exists; skipping\n",
      "⏭️  batch_39_out.jsonl already exists; skipping\n",
      "⏭️  batch_37_out.jsonl already exists; skipping\n",
      "⏭️  batch_35_out.jsonl already exists; skipping\n",
      "⏭️  batch_34_out.jsonl already exists; skipping\n",
      "⏭️  batch_32_out.jsonl already exists; skipping\n",
      "⏭️  batch_31_out.jsonl already exists; skipping\n",
      "⏭️  batch_28_out.jsonl already exists; skipping\n",
      "↷ Batch batch_6899ec841074819095326dc1c3345920: status=failed (not downloaded)\n",
      "↷ Batch batch_6899ec78cf108190b5b2c925e8dd6bb7: status=failed (not downloaded)\n",
      "⏭️  batch_33_out.jsonl already exists; skipping\n",
      "↷ Batch batch_6899ec6b755481909291916a3f48c1eb: status=failed (not downloaded)\n",
      "↷ Batch batch_6899ec66c7d881908254c6748a610120: status=failed (not downloaded)\n",
      "↷ Batch batch_6899ec5e74cc8190bb0de906d58c447c: status=failed (not downloaded)\n",
      "↷ Batch batch_6899378256c08190b61948d27ddbd71c: status=failed (not downloaded)\n",
      "⏭️  batch_38_out.jsonl already exists; skipping\n",
      "↷ Batch batch_689937584c948190bb7bb509ce271fd2: status=failed (not downloaded)\n",
      "⏭️  batch_36_out.jsonl already exists; skipping\n",
      "↷ Batch batch_6899372e49a48190adaa904f19c5e180: status=failed (not downloaded)\n",
      "↷ Batch batch_689937196a208190b593c9423d6cc102: status=failed (not downloaded)\n",
      "↷ Batch batch_6899370442a08190a2b4307a5c64e5d5: status=failed (not downloaded)\n",
      "↷ Batch batch_689936ef363481909794bc978842f356: status=failed (not downloaded)\n",
      "↷ Batch batch_689936da184481909d6e4dc7d541b538: status=failed (not downloaded)\n",
      "⏭️  batch_30_out.jsonl already exists; skipping\n",
      "⏭️  batch_29_out.jsonl already exists; skipping\n",
      "↷ Batch batch_6899369ae0748190b2401891cf7d6da2: status=failed (not downloaded)\n",
      "⏭️  batch_27_out.jsonl already exists; skipping\n",
      "⏭️  batch_26_out.jsonl already exists; skipping\n",
      "⏭️  batch_24_out.jsonl already exists; skipping\n",
      "↷ Batch batch_6898aa0bb748819094aba6eea5472360: status=failed (not downloaded)\n",
      "⏭️  batch_25_out.jsonl already exists; skipping\n",
      "↷ Batch batch_6898a051f3ac8190b06bd65aa81c23d9: status=failed (not downloaded)\n",
      "⏭️  batch_23_out.jsonl already exists; skipping\n",
      "⏭️  batch_22_out.jsonl already exists; skipping\n",
      "⏭️  batch_21_out.jsonl already exists; skipping\n",
      "⏭️  batch_20_out.jsonl already exists; skipping\n",
      "⏭️  batch_19_out.jsonl already exists; skipping\n",
      "⏭️  batch_18_out.jsonl already exists; skipping\n",
      "⏭️  batch_17_out.jsonl already exists; skipping\n",
      "⏭️  batch_16_out.jsonl already exists; skipping\n",
      "⏭️  batch_15_out.jsonl already exists; skipping\n",
      "⏭️  batch_14_out.jsonl already exists; skipping\n",
      "⏭️  batch_13_out.jsonl already exists; skipping\n",
      "⏭️  batch_12_out.jsonl already exists; skipping\n",
      "⏭️  batch_11_out.jsonl already exists; skipping\n",
      "⏭️  batch_10_out.jsonl already exists; skipping\n",
      "⏭️  batch_9_out.jsonl already exists; skipping\n",
      "⏭️  batch_8_out.jsonl already exists; skipping\n",
      "⏭️  batch_7_out.jsonl already exists; skipping\n",
      "⏭️  batch_6_out.jsonl already exists; skipping\n",
      "⏭️  batch_5_out.jsonl already exists; skipping\n",
      "⏭️  batch_4_out.jsonl already exists; skipping\n",
      "⏭️  batch_3_out.jsonl already exists; skipping\n",
      "⏭️  batch_2_out.jsonl already exists; skipping\n",
      "⏭️  batch_1_out.jsonl already exists; skipping\n",
      "⏭️  batch_0_out.jsonl already exists; skipping\n",
      "⏭️  batch_23_out.jsonl already exists; skipping\n",
      "⏭️  batch_22_out.jsonl already exists; skipping\n",
      "⏭️  batch_21_out.jsonl already exists; skipping\n",
      "⏭️  batch_20_out.jsonl already exists; skipping\n",
      "⏭️  batch_19_out.jsonl already exists; skipping\n",
      "⏭️  batch_18_out.jsonl already exists; skipping\n",
      "⏭️  batch_17_out.jsonl already exists; skipping\n",
      "⏭️  batch_16_out.jsonl already exists; skipping\n",
      "⏭️  batch_15_out.jsonl already exists; skipping\n",
      "⏭️  batch_14_out.jsonl already exists; skipping\n",
      "⏭️  batch_13_out.jsonl already exists; skipping\n",
      "⏭️  batch_12_out.jsonl already exists; skipping\n",
      "⏭️  batch_11_out.jsonl already exists; skipping\n",
      "⏭️  batch_10_out.jsonl already exists; skipping\n",
      "⏭️  batch_9_out.jsonl already exists; skipping\n",
      "⏭️  batch_8_out.jsonl already exists; skipping\n",
      "⏭️  batch_7_out.jsonl already exists; skipping\n",
      "⏭️  batch_6_out.jsonl already exists; skipping\n",
      "⏭️  batch_5_out.jsonl already exists; skipping\n",
      "⏭️  batch_4_out.jsonl already exists; skipping\n",
      "⏭️  batch_3_out.jsonl already exists; skipping\n",
      "⏭️  batch_2_out.jsonl already exists; skipping\n",
      "⏭️  batch_1_out.jsonl already exists; skipping\n",
      "⏭️  batch_0_out.jsonl already exists; skipping\n",
      "↷ Batch batch_6888ee7d51708190aed14c244919367e: status=failed (not downloaded)\n",
      "⏭️  batch_0_out.jsonl already exists; skipping\n",
      "⏭️  batch_3_out.jsonl already exists; skipping\n",
      "⏭️  batch_2_out.jsonl already exists; skipping\n",
      "↷ Batch batch_687ffef1a3288190a55dbb2a7831ede7: status=failed (not downloaded)\n",
      "↷ Batch batch_687ff2cbc4648190ba437f9229609136: status=failed (not downloaded)\n",
      "⏭️  batch_1_out.jsonl already exists; skipping\n",
      "↷ Batch batch_687ff151b28081909fe4319c979cc5d8: status=failed (not downloaded)\n",
      "↷ Batch batch_687fbe7798fc8190b67d6b7406f1b25b: status=failed (not downloaded)\n",
      "↷ Batch batch_687fa9d996548190a4163d4035e00195: status=failed (not downloaded)\n",
      "⏭️  batch_0_out.jsonl already exists; skipping\n",
      "↷ Batch batch_687f9bd29fc08190b41813439a802650: status=failed (not downloaded)\n",
      "↷ Batch batch_687f9927c7208190a3440db5b8c12fca: status=failed (not downloaded)\n",
      "↷ Batch batch_687f980bc6a88190b6ec2d6fa7776b61: status=failed (not downloaded)\n",
      "↷ Batch batch_687f96d574a481909ecc029516e9d122: status=cancelled (not downloaded)\n",
      "\n",
      "=== Summary ===\n",
      "Downloaded: 20\n",
      "Skipped:    90\n",
      "Waiting:    0 (not completed yet)\n",
      "Errors:     0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download OpenAI Batch outputs and name them after their input file (+ '_out').\n",
    "\n",
    "Requirements:\n",
    "  - pip install openai\n",
    "  - Set environment variable: OPENAI_API_KEY\n",
    "Usage:\n",
    "  - Edit OUTPUT_DIR below, or pass a path to download_batch_outputs(output_dir=...)\n",
    "  - Optional: pass a list of batch IDs to download only those batches.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "from openai import OpenAI\n",
    "import apikey\n",
    "# === CONFIG ===\n",
    "OUTPUT_DIR = r\"D:\\vc-research\\reese data\\downloaded_batches\"  # <-- change as you like\n",
    "\n",
    "client = OpenAI( api_key=apikey.get_api_key())\n",
    "\n",
    "\n",
    "# Set your API key\n",
    "\n",
    "def safe_mkdir(path: str | Path) -> Path:\n",
    "    p = Path(path)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def filename_from_input_file(input_file_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the original filename of the uploaded input file.\n",
    "    Fallback to the file ID if the name isn't available.\n",
    "    \"\"\"\n",
    "    f = client.files.retrieve(input_file_id)\n",
    "    return getattr(f, \"filename\", None) or input_file_id\n",
    "\n",
    "def build_output_name(input_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Turn 'batch_0.jsonl' -> 'batch_0_out.jsonl'\n",
    "    If there is no extension, just append '_out.jsonl'.\n",
    "    \"\"\"\n",
    "    stem = Path(input_filename).stem  # 'batch_0'\n",
    "    return f\"{stem}_out.jsonl\"\n",
    "\n",
    "\n",
    "\n",
    "def download_file(file_id: str, dest_path: Path) -> None:\n",
    "    resp = client.files.content(file_id)   # returns a readable object\n",
    "    data = resp.read()                     # just call .read(), no \"with\"\n",
    "    dest_path.write_bytes(data)\n",
    "\n",
    "\n",
    "def list_completed_batches(limit: int = 1000):\n",
    "    \"\"\"\n",
    "    Generator over completed batches (status == 'completed').\n",
    "    Paginates through all batches up to `limit`.\n",
    "    \"\"\"\n",
    "    fetched = 0\n",
    "    after = None\n",
    "    while fetched < limit:\n",
    "        resp = client.batches.list(limit=min(100, limit - fetched), after=after)\n",
    "        if not resp.data:\n",
    "            break\n",
    "        for b in resp.data:\n",
    "            yield b\n",
    "        fetched += len(resp.data)\n",
    "        # batches are returned sorted by created time desc; pagination token:\n",
    "        after = resp.last_id\n",
    "        if not after:\n",
    "            break\n",
    "\n",
    "def resolve_batches(batch_ids: Optional[Iterable[str]] = None):\n",
    "    \"\"\"\n",
    "    Yield batch objects either by specific IDs or all completed batches.\n",
    "    \"\"\"\n",
    "    if batch_ids:\n",
    "        for bid in batch_ids:\n",
    "            yield client.batches.retrieve(bid)\n",
    "    else:\n",
    "        yield from list_completed_batches()\n",
    "\n",
    "def download_batch_outputs(\n",
    "    output_dir: str | Path = OUTPUT_DIR,\n",
    "    batch_ids: Optional[Iterable[str]] = None,\n",
    "    skip_existing: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Download outputs for completed batches, naming them after their input file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_dir : directory to save outputs\n",
    "    batch_ids : iterable of batch IDs to restrict downloads; if None, process all completed batches\n",
    "    skip_existing : if True, do not overwrite files already present\n",
    "    \"\"\"\n",
    "    outdir = safe_mkdir(output_dir)\n",
    "\n",
    "    count_ok = 0\n",
    "    count_skip = 0\n",
    "    count_waiting = 0\n",
    "    count_error = 0\n",
    "\n",
    "    for batch in resolve_batches(batch_ids):\n",
    "        status = getattr(batch, \"status\", \"unknown\")\n",
    "        input_file_id = getattr(batch, \"input_file_id\", None)\n",
    "        output_file_id = getattr(batch, \"output_file_id\", None)\n",
    "        error_file_id = getattr(batch, \"error_file_id\", None)\n",
    "\n",
    "        # Only proceed if completed\n",
    "        if status != \"completed\":\n",
    "            print(f\"↷ Batch {batch.id}: status={status} (not downloaded)\")\n",
    "            if status in {\"finalizing\", \"in_progress\"}:\n",
    "                count_waiting += 1\n",
    "            continue\n",
    "\n",
    "        if not input_file_id:\n",
    "            print(f\"⚠️  Batch {batch.id}: missing input_file_id; skipping\")\n",
    "            count_error += 1\n",
    "            continue\n",
    "\n",
    "        if not output_file_id:\n",
    "            # Batch completed but no output file (should be rare); surface error file if present\n",
    "            msg = f\"⚠️  Batch {batch.id}: completed but no output_file_id\"\n",
    "            if error_file_id:\n",
    "                msg += f\" (error_file_id={error_file_id})\"\n",
    "            print(msg)\n",
    "            count_error += 1\n",
    "            continue\n",
    "\n",
    "        # Get the original input filename and build the destination name\n",
    "        input_filename = filename_from_input_file(input_file_id)\n",
    "        out_name = build_output_name(input_filename)\n",
    "        dest = outdir / out_name\n",
    "\n",
    "        if skip_existing and dest.exists():\n",
    "            print(f\"⏭️  {dest.name} already exists; skipping\")\n",
    "            count_skip += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            download_file(output_file_id, dest)\n",
    "            print(f\"✅  Saved: {dest}\")\n",
    "            count_ok += 1\n",
    "        except Exception as e:\n",
    "            print(f\"❌  Failed to save {dest.name} from batch {batch.id}: {e}\")\n",
    "            count_error += 1\n",
    "\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"Downloaded: {count_ok}\")\n",
    "    print(f\"Skipped:    {count_skip}\")\n",
    "    print(f\"Waiting:    {count_waiting} (not completed yet)\")\n",
    "    print(f\"Errors:     {count_error}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    #   - To process ALL completed batches: just run the script as-is.\n",
    "    #   - To target specific batches, pass their IDs:\n",
    "    #       download_batch_outputs(batch_ids=[\"batch_abc123\", \"batch_def456\"])\n",
    "    download_batch_outputs(output_dir=OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
